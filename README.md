# Fleet Health Ontology & Predictive Maintenance Demo

This project demonstrates how to standardize operational data, apply a reusable ontology for semantic relationships, and generate both analytical features and graph-based representations to support proactive maintenance and reliability engineering.

The demo includes:

- A **data ingestion and standardization pipeline**
- A **domain ontology** for aircraft, components, work orders, alerts, and telemetry
- Automatic **feature generation** for aircraft health scoring
- Static and interactive **entity-relationship graphs** generated from the ontology
- Neo4j-compatible **Cypher export**
- A **Streamlit UI** for running, inspecting, and visualizing each stage of the workflow

This structure generalizes well to:
- Fleet operations (aviation, automotive, heavy equipment)
- Predictive maintenance programs
- Reliability engineering / condition-based maintenance
- Semantic modeling for AI/ML readiness


---

## Key Concepts

### Ontology-Driven Data Architecture
Instead of treating tables independently, domain entities (Aircraft, Sensors, Parts, Work Orders, Alerts) are connected through defined **relationships**.  
This enables:
- Self-service data discovery
- Context-aware analytics (telemetry → maintenance → parts usage → root cause)
- Future extensibility into graph databases & AI reasoning engines

### Predictive Maintenance Feature Framework
The pipeline produces standardized feature tables that quantify equipment health, such as:
- Sensor rolling averages & anomaly deltas
- Failure pattern indicators
- Maintenance recency scores
- Alert severity aggregations

These features can feed:
- Time-series forecasting models
- Health scoring dashboards
- Model-based decision assistance

---

## Repository Structure
├── streamlit_app.py                  # Interactive UI
├── data/
│   ├── raw/                          # Input / sample data (replaceable with real feeds)
│   └── standardized/                 # Output tables generated by the pipeline
├── ontology/
│   ├── concepts.json                 # Entity definitions & tagging
│   └── relationships.json            # Directed graph of operational relationships
├── artifacts/
│   ├── ontology_graph.png            # Static topology visualization
│   └── ontology_graph_interactive.html  # Interactive physics-enabled graph
├── scripts/
│   ├── ingest.py                     # Data ingestion / cleaning
│   ├── validate.py                   # Schema & quality checks
│   ├── ontology_graph.py             # Static graph renderer
│   └── interactive_graph.py          # Interactive vis-network HTML graph generator
└── requirements.txt

---

## Quick Start

### 1 Create and activate a virtual environment
```bash
python -m venv .venv
source .venv/bin/activate   # macOS / Linux
# OR
.\.venv\Scripts\Activate     # Windows
```
### 2 install Requirements
```bash
pip install -r requirements.txt
```
### 3 Launch the UI
```bash
streamlit run streamlit_app.py
```
-----
## Running the Pipeline (in the UI)
Step 1 
Action: Build Data
Result: Standardizes raw tables → populates data/standardized/

Step 2
Action: Validate
Result: Runs schema, format, and sanity checks

Step 3:
Action: Render Ontology Graph
Results: Creates static PNG graph of entity topology

Step 4:
Action: Build Interactive Graph
Results: Generates interactive vis-network HTML graph

Step 5:
Action: Generate Cypher
Results: Creates Neo4j import script aligning entities & relationships

------
## Why this matters

Traditional dashboards answer what happened.
This model answers why, how, and what to do next.

By encoding relationships, not just tables:
	•	Maintenance teams get contextualized diagnostics
	•	Data engineering reduces friction and duplication
	•	ML models become explainable and operationally relevant
	•	Leadership gains a scalable foundation for AI-ready data